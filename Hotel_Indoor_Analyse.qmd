---
# Headline
title: "<img src='resources/images/logo/telekom.png' style='width: 200px; height: auto; padding-left: 100px;'> 
    <span style='padding-left: 75px; padding-right: 75px;'>Hotel Indoor Analyse</span> 
    <img src='resources/images/logo/fhdw.png' style='width: 120px; height: auto;'>"
author: 
  name: "Cedric Klöpsch"
  affiliations: " Telekom & FHDW"
date: today

title-block-banner: "#FFFFFF"
title-block-banner-color: "#E20075"

theme: cosmo

# description: ""

# Formatting
lang: "DE"
format:
  html:
    toc: true
    toc-title: Inhaltsverzeichnis 
    toc-float: true
    number-sections: true
    smooth-scroll: true
    code-fold: true
    code-summary: "Code anzeigen"
    code-links:
      - text: Github Repo
        icon: file-code
        href: https://github.com/Obscrts/DAML
    embed-resources: true
  pdf:
    toc: true
    toc-title: Inhaltsverzeichnis 
    toc-float: true
    number-sections: true
    smooth-scroll: true
    code-fold: true
    code-summary: "Code anzeigen"
    code-links:
      - text: Github Repo
        icon: file-code
        href: https://github.com/Obscrts/DAML
    embed-resources: true
execute:
  echo: true
  eval: true
  output: asis
  warning: false
  message: false
  error: false
  embed: false
  cache: true
jupyter: python3
---

# Überblick über den Datensatz
Die Daten stammen aus dem Mobilfunknetz der Deutschen Telekom und wurden mit dem NitroGEO-Tool von Viavi extrahiert. Es handelt sich um Mobilfunkdaten, die als "Indoor" klassifiziert wurden, was bedeutet, dass die jeweiligen Endnutzergeräte zum Zeitpunkt der Erfassung mit hoher Wahrscheinlichkeit innerhalb eines Gebäudes waren. Der Datensatz umfasst mehrere große deutsche Städte, die Austragungsorte der Fußball-Europameisterschaft 2024 waren: Berlin, Köln, Dortmund, Düsseldorf, Frankfurt am Main, Gelsenkirchen, Hamburg, Leipzig, München und Stuttgart.

Zusätzlich zum Hauptdatensätzen, die die tatsächlichen Hotelbereiche abdecken, gibt es einen zweiten Datensatz, der sogenannte **Buffered Polygons**(gepufferte Polygone) enthält. Diese Polygone sind größer als die tatsächlichen Hotelbereiche und wurden erstellt, um die Umgebung um die Hotels zu analysieren. Beide Datensätze enthalten dieselben Mobilfunkmetriken, jedoch mit unterschiedlichen räumlichen Ausdehnungen.

Die enthaltenen Messwerte umfassen wichtige Metriken wie Timing Advance (TA), RSRP (Reference Signal Received Power) und RSRQ (Reference Signal Received Quality), die Informationen über die Signalqualität und die Reichweite innerhalb und außerhalb von Gebäuden liefern. Ein dritter Datensatz in Form einer **GeoJSON-Datei** gibt Aufschluss über die geografische Lage und Größe der Polygone, um eine räumliche Analyse durchzuführen.

Eine detaillierte Erklärung der Metriken und deren Bedeutung erfolgt im weiteren Verlauf der Analyse.

## Thesen

1. **Hotels mit höherem Timing Advance (TA) haben im Durchschnitt eine schlechtere Signalqualität (RSRP, RSRQ)**

   - **Begründung**: Timing Advance (TA) gibt die Entfernung des Endgeräts zur Basisstation an. Es ist zu erwarten, dass mit zunehmender Entfernung (größeres TA) die Signalqualität (RSRP/RSRQ) schlechter wird.

   - **Mögliche Analyse**: Korrelation zwischen TA und den Signalqualitätsmetriken RSRP/RSRQ; Erstellung von Scatterplots; lineare Regressionsmodelle.

2. **Hotels in dichter besiedelten Gebieten haben im Durchschnitt eine schlechtere Netzqualität als Hotels in weniger dicht besiedelten Gebieten**

   - **Begründung**: Städtische Gebiete haben tendenziell mehr Netzwerkauslastung, was zu schlechteren Signalstärken und höheren Verbindungsfehlern führen könnte.
   
   - **Mögliche Analyse**: Durch den Einsatz von geospatialen Daten und den Polygonflächen könnte untersucht werden, ob Hotels in urbanen Gebieten signifikant schlechtere Netzqualitäten aufweisen. Eine Clusteranalyse könnte basierend auf der geografischen Lage und den Signalqualitäten durchgeführt werden.

3. **Hotels mit hoher Datenübertragungsrate (DL/UL Throughput) zeigen eine bessere Signalqualität (RSRP, RSRQ) als Hotels mit niedriger Datenübertragungsrate**

   - **Begründung**: Eine bessere Signalqualität sollte mit höheren Datenübertragungsraten (DL/UL Throughput) einhergehen.

   - **Mögliche Analyse**: Untersuchung der Korrelation zwischen DL/UL Throughput und den Signalqualitätsmetriken; Erstellung von Scatterplots; lineare Regression.

4. **Es existieren räumliche Cluster von Hotels mit ähnlicher Netzqualität in bestimmten geographischen Regionen**

   - **Begründung**: Geografische Faktoren wie die Nähe zu Netzwerkinfrastrukturen oder das städtische/rurale Umfeld könnten Einfluss auf die Netzqualität nehmen.

   - **Mögliche Analyse**: Verwendung der GeoJSON-Daten zur Darstellung der geographischen Verteilung der Hotels und deren Netzqualität; Erstellung von Karten; räumliche Clusteranalyse.

## Importierte Bibliotheken
| **Bibliothek**   | **Beschreibung**                                                                                                                                           |
|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `pandas`      | Eine leistungsstarke Bibliothek zur Datenmanipulation und -analyse. Sie wird verwendet, um Daten aus CSV-Dateien zu laden und in einem DataFrame-Format darzustellen. |
| `geopandas`    | Eine Erweiterung von Pandas für räumliche Daten. Sie ermöglicht das Laden geografischer Daten und speichert sie in einem GeoDataFrame für Geometrieanalysen. |
| `numpy`        | Bietet mathematische Funktionen für numerische Operationen und unterstützt insbesondere bei der Verarbeitung großer Datenmengen und Arrays.                |
| `matplotlib`   | Wird für die Erstellung von Visualisierungen verwendet. Ermöglicht die Erstellung von Diagrammen, Graphen und anderen Darstellungen zur Mustererkennung.   |
| `seaborn`      | Erleichtert das Erstellen informativer Visualisierungen, baut auf matplotlib auf und bietet erweiterte Funktionen für die Visualisierung von Datenbeziehungen. |
| `os`           | Dient zur Interaktion mit dem Betriebssystem, insbesondere zur Arbeit mit Dateistrukturen und Dateipfaden für den Zugriff auf CSV-Dateien.   |
 `scikit-learn`  | Bietet eine Vielzahl von Machine-Learning-Algorithmen, z. B. für lineare Regression und Random Forests, zum Trainieren und Evaluieren von Modellen.  |
```{python}
#| label: setup - importing libraries
#| include: false

import pandas as pd
import geopandas as gpd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.impute import SimpleImputer

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.cluster import KMeans

from matplotlib.colors import Normalize
from matplotlib.cm import ScalarMappable
```

## Einlesen des Datensatzes
In diesem Abschnitt werden die normalen Hotel-Daten und die gepufferten Polygone für die verschiedenen Städte eingelesen und zusammengeführt. Die normalen Daten repräsentieren die tatsächlichen Hotelbereiche, während die gepufferten Polygone größere Bereiche um die Hotels herum abdecken, um auch die Umgebung zu analysieren.

Jeder Datensatz wird mit einer zusätzlichen Spalte versehen, die kennzeichnet, ob es sich um normale oder gepufferte Daten handelt. Zudem wird der Name der jeweiligen Stadt in den Datensatz aufgenommen, um die Analyse später nach Städten segmentieren zu können.

### Vorgehen:
**Einlesen und Zusammenführen der Daten für jede Stadt**<br/>
Zuerst werden die normalen Daten, die die tatsächlichen Hotelbereiche abdecken, eingelesen. 
```{python}
#| label: loading normal dataset

# Liste der Stadtkürzel
cities = ['BER', 'CGN', 'DOR', 'DUS', 'FFM', 'GEL', 'HH', 'LPZ', 'MUC', 'STG']

# Leere Liste für normale Daten
normal_data = []

# Einlesen der normalen CSV-Daten für jede Stadt
for city in cities:
    normal_path = f'resources/data/normal/geo_export_{city}.csv'
    normal_df = pd.read_csv(normal_path)
    
    # Hinzufügen eines Identifikators, um die Daten als normal zu kennzeichnen
    normal_df['type'] = 'normal'
    
    # Hinzufügen der Stadt als Spalte
    normal_df['city'] = city
    
    # Speichern der normalen Daten
    normal_data.append(normal_df)

# Zusammenführen aller normalen Daten
normal_combined_df = pd.concat(normal_data, ignore_index=True)
```
<br/>
**Einlesen der gepufferten Daten**<br/>
Nun werden die gepufferten Polygone eingelesen, die größere Bereiche um die Hotels abdecken.
```{python}
#| label: loading buffered dataset

# Leere Liste für gepufferte Daten
buffered_data = []

# Einlesen der gepufferten CSV-Daten für jede Stadt
for city in cities:
    buffered_path = f'resources/data/buffered/polygon_kpi_{city}.csv'
    buffered_df = pd.read_csv(buffered_path)
    
    # Hinzufügen eines Identifikators, um die Daten als gepuffert zu kennzeichnen
    buffered_df['type'] = 'buffered'
    
    # Hinzufügen der Stadt als Spalte
    buffered_df['city'] = city
    
    # Speichern der gepufferten Daten
    buffered_data.append(buffered_df)

# Zusammenführen aller gepufferten Daten
buffered_combined_df = pd.concat(buffered_data, ignore_index=True)
```
<br/>
**Zusammenführen der normalen und gepufferten Daten**<br/>
Nachdem die normalen und gepufferten Daten separat eingelesen wurden, werden sie nun zu einem finalen DataFrame kombiniert.
```{python}
#| label: combining both dataset

# Kombinieren der normalen und gepufferten Daten
combined_df = pd.concat([normal_combined_df, buffered_combined_df], ignore_index=True)
```
<br/>

## Berechnung der Polygonflächen

In diesem Abschnitt werden die Flächen der Polygone berechnet, die die geografischen Bereiche der Hotels und deren Umgebung beschreiben. Diese Polygone wurden in **GeoJSON**-Dateien gespeichert, die jede Stadt und deren Hotelbereiche repräsentieren.

Um die Flächen der Polygone zu berechnen, werden die GeoJSON-Dateien für jede Stadt eingelesen und die geometrischen Informationen extrahiert. Dabei konvertieren wir die Geometrien in ein metrisches Koordinatensystem (z.B. **UTM Zone 33N**), um die Flächen in Quadratmetern zu berechnen. Zusätzlich wird eine eindeutige **Name**-Spalte erstellt, die aus der **Cluster-ID** und der **Polygon-ID** besteht, um die Polygone später mit den entsprechenden Hotel-Daten zu verknüpfen.

### Vorgehen:

1. **Einlesen der GeoJSON-Dateien**: Alle GeoJSON-Dateien, die die Polygone der Hotels repräsentieren, werden eingelesen.

2. **Koordinatensystem-Umwandlung**: Um die Flächen korrekt zu berechnen, werden die Geometrien in ein metrisches Koordinatensystem konvertiert.

3. **Berechnung der Flächen**: Für jedes Polygon wird die Fläche in Quadratmetern berechnet.

4. **Erstellen der **Name**-Spalte**: Der Name wird basierend auf der Cluster-ID und der Polygon-ID generiert, um die Daten später mit den Hotels zu verknüpfen.

```{python}
#| label: calculate polygon area sizes

# Liste der GeoJSON-Dateien (cluster_01 bis cluster_99)
cluster_files = [f'resources/data/polygons/cluster_{i:02}.geojson' for i in range(1, 100)]

# Dateien, die ausgeschlossen werden sollen
excluded_files = [
    'resources/data/polygons/cluster_05.geojson',
    'resources/data/polygons/cluster_11.geojson',
    'resources/data/polygons/cluster_43.geojson',
    'resources/data/polygons/cluster_62.geojson'
]

# Liste, um die Ergebnisse zu speichern
polygon_areas = []

# Einlesen der GeoJSON-Dateien und Berechnung der Polygonflächen
for cluster_file in cluster_files:
    # Überspringen der ausgeschlossenen Dateien
    if cluster_file in excluded_files:
        continue
    
    try:
        # Einlesen der GeoJSON-Datei
        gdf = gpd.read_file(cluster_file)
        
        # Sicherstellen, dass der GeoDataFrame in einem metrischen Koordinatensystem vorliegt
        gdf = gdf.to_crs(epsg=32633)  # Beispiel: UTM Zone 33N (anpassen, falls notwendig)
        
        # Berechnung der Fläche jedes Polygons (in Quadratmetern)
        gdf['area_m2'] = gdf.geometry.area
        
        # Extrahieren der Cluster-ID aus dem Dateinamen
        cluster_id = cluster_file.split('_')[-1].split('.')[0]  # Gibt z.B. "01" für "cluster_01.geojson" zurück
        
        # Generieren des Namens nach dem Schema XX#YY, wobei XX die Cluster-ID und YY die Polygon-ID ist
        gdf['name'] = [f"{cluster_id}#{str(i+1).zfill(2)}" for i in range(len(gdf))]
        
        # Speichern der Ergebnisse (Name des Polygons und seine Fläche)
        polygon_areas.append(gdf[['name', 'area_m2']])
        
    except FileNotFoundError:
        print(f"GeoJSON-Datei {cluster_file} nicht gefunden.")
    except Exception as e:
        print(f"Fehler bei der Verarbeitung von {cluster_file}: {e}")

# Alle Polygonflächen zusammenführen
polygon_areas_df = pd.concat(polygon_areas, ignore_index=True)

# Anzeigen der ersten Zeilen der berechneten Flächen mit den generierten Namen
display(polygon_areas_df.head(10))
```

Abschließend wird der kombinierte Datensatz der Hoteldaten mit den berechneten Polygongrößen erweitert, um so einen einzign Datensatz mit allen Informationen zu erhalten.
```{python}
#| label: combine hotel dataset with polygon area

# Extrahieren des Cluster-ID#Polygon-ID-Teils (z.B. "10#01" aus "10#01 Hotel Berlin, Berlin")
combined_df['extracted_name'] = combined_df['Name'].str.extract(r'(\d{2}#\d{2})')

# Nun führen wir den Merge durch, indem wir die extrahierten Namen und die Polygon 'name'-Spalte verwenden
final_combined_df = pd.merge(combined_df, polygon_areas_df, left_on='extracted_name', right_on='name', how='left')

# Entfernen der Spalten "name" und "extracted_name" aus dem finalen DataFrame
final_combined_df.drop(['name', 'extracted_name'], axis=1, inplace=True)
```

## Beschreibung der wichtigsten Spalten

In diesem Abschnitt werden die relevantesten Spalten des Datensatzes beschrieben, die für die Analyse der Mobilfunknetzqualität von Bedeutung sind. Diese Metriken sind entscheidend, um die Netzqualität sowie die Verbindungsstabilität und -leistung zu bewerten.

### RSRP Avg (dBm)
   - **Beschreibung**: *Reference Signal Received Power* (RSRP) ist eine Metrik, die die empfangene Signalstärke eines Mobilfunkgeräts in Dezibel Milliwatt (dBm) misst.

   - **Bedeutung**: Diese Metrik gibt an, wie stark das Mobilfunksignal ist, das von der Basisstation zum Endgerät gesendet wird. Je höher der RSRP-Wert, desto besser ist die Signalstärke. Typische Werte liegen zwischen -140 dBm (schlecht) und -44 dBm (sehr gut).

   - **Interpretation**: RSRP ist eine Schlüsselmetrik zur Bewertung der Verbindungsqualität. Schwache Werte deuten darauf hin, dass das Endgerät möglicherweise weit von der Basisstation entfernt ist oder Hindernisse die Signalstärke beeinträchtigen.

### RSRQ Avg (dB)
   - **Beschreibung**: *Reference Signal Received Quality* (RSRQ) misst die Qualität des empfangenen Signals in Dezibel (dB).

   - **Bedeutung**: RSRQ gibt an, wie effizient das Mobilfunkgerät das empfangene Signal verwendet. Typische Werte liegen zwischen -3 dB (sehr gut) und -19 dB (schlecht). Niedrigere Werte deuten auf eine stärkere Interferenz oder eine hohe Netzwerkauslastung hin.

   - **Interpretation**: RSRQ ist besonders nützlich zur Beurteilung der Signalqualität in überlasteten Netzwerken. Zusammen mit RSRP kann diese Metrik verwendet werden, um festzustellen, ob die Signalqualität durch Interferenzen oder Netzwerkauslastung beeinträchtigt ist.

### TA Avg (m)
   - **Beschreibung**: *Timing Advance* (TA) misst die Entfernung zwischen dem Mobilfunkgerät und der Basisstation in Metern.

   - **Bedeutung**: Ein höherer TA-Wert bedeutet, dass das Mobilfunkgerät weiter von der Basisstation entfernt ist. Dies kann zu einer schlechteren Signalqualität und höheren Latenzen führen.

   - **Interpretation**: TA ist wichtig, um zu verstehen, wie weit ein Gerät von der Basisstation entfernt ist. Höhere TA-Werte können zusammen mit niedrigeren RSRP-Werten verwendet werden, um Verbindungsprobleme zu diagnostizieren.

### DL Volume (MB) & UL Volume (MB)
   - **Beschreibung**: Diese Metriken messen das Volumen der Daten, die im Downlink (DL) und Uplink (UL) übertragen werden, in Megabyte (MB).

   - **Bedeutung**: Diese Metriken sind ein Maß für die Datenmenge, die zwischen dem Endgerät und der Basisstation fließt. Ein hohes Volumen deutet auf eine intensive Nutzung des Netzwerks hin.

   - **Interpretation**: Sie werden verwendet, um die Netzwerkauslastung und die Leistung des Netzwerks bei Datenübertragungen zu bewerten.

### DL Throughput Avg (Mbps) & UL Throughput Avg (Mbps)
   - **Beschreibung**: Diese Metriken messen die durchschnittliche Datenübertragungsrate im Downlink (DL) und Uplink (UL) in Megabit pro Sekunde (Mbps).

   - **Bedeutung**: Höhere Durchsatzwerte deuten auf eine gute Netzwerkleistung hin, während niedrige Werte auf Engpässe oder eine schlechte Signalqualität hinweisen können.

   - **Interpretation**: Der durchschnittliche Durchsatz ist ein wichtiger Indikator für die Nutzererfahrung, insbesondere bei datenintensiven Anwendungen wie Videostreaming oder großen Dateiübertragungen.

### CQI Avg
   - **Beschreibung**: Der *Channel Quality Indicator* (CQI) gibt an, wie gut der Kanal zwischen dem Mobilfunkgerät und der Basisstation ist.

   - **Bedeutung**: CQI-Werte reichen von 1 (schlecht) bis 15 (sehr gut). Diese Metrik beeinflusst direkt die Modulation und Codierung, die das Netzwerk verwendet, um die Verbindung zu verwalten.

   - **Interpretation**: Ein höherer CQI-Wert führt zu besseren Datenübertragungsraten, da das Netzwerk effizientere Modulations- und Kodierungstechniken verwenden kann.

### RRC Connection Setup Failure Rate (%)
   - **Beschreibung**: Misst die Rate der fehlgeschlagenen Verbindungsaufbauversuche zwischen einem Endgerät und dem Netzwerk in Prozent.

   - **Bedeutung**: Eine hohe Fehlerquote weist darauf hin, dass viele Verbindungsanfragen nicht erfolgreich abgeschlossen werden. Dies kann auf Netzwerkprobleme, Überlastung oder eine schlechte Signalqualität hindeuten.

   - **Interpretation**: Diese Metrik ist entscheidend, um die Stabilität des Netzwerks zu bewerten, insbesondere in Gebieten mit hoher Netzauslastung.
---

Diese Metriken spielen eine Schlüsselrolle bei der Analyse der Netzwerkkonfiguration und -leistung. Jede dieser Spalten bietet wertvolle Informationen über die Signalstärke, die Verbindungsqualität und die allgemeine Leistungsfähigkeit des Mobilfunknetzes.

## Erste Betrachtung des Datensatzes
Bevor wir in die detaillierte Analyse einsteigen, werfen wir einen ersten Blick auf die Struktur des kombinierten Datensatzes. Dies hilft uns, die enthaltenen Spalten, die Datentypen und die ersten Werte zu verstehen. Der Datensatz enthält Informationen sowohl aus den normalen Hotel-Daten als auch den buffered polygons, wobei jeder Eintrag mit einem Typ (normal oder buffered) und einer Stadt versehen ist.

Im nächsten Schritt zeigen wir die ersten Zeilen des Datensatzes an, um sicherzustellen, dass alle Daten korrekt geladen und kombiniert wurden.

```{python}
#| label: first look on combined df

display(final_combined_df[['Period Start Time', 'Name', 'RRC Connection Setup Attempts', 'RSRP Avg (dBm)', 'RSRQ Avg (dB)', 'TA Avg (m)', 'area_m2']].head())
```

# Vergleich der Datensätze
In diesem Abschnitt vergleichen wir die **Hotel-Daten** mit denen der **Buffered Polygon-Daten**, um Unterschiede in den Metriken zu identifizieren. Die normalen Hotel-Daten repräsentieren die tatsächlichen Hotelbereiche, während die Buffered Polygon-Daten größere, gepufferte Bereiche um die Hotels abdecken.

## Vorgehensweise:
- **Segmentierung nach Typ**: Wir segmentieren den kombinierten Datensatz in die zwei Kategorien *normal* (Hotel-Daten) und *buffered* (Buffered Polygon-Daten).

- **Statistischer Vergleich**: Für jede Gruppe berechnen wir Mittelwert, Median und Standardabweichung relevanter Metriken, wie TA, RSRP und RSRQ. Dies gibt uns Aufschluss darüber, wie sich die Netzqualität zwischen den tatsächlichen Hotelbereichen und den gepufferten Zonen unterscheidet.
```{python}
#| label: compare datasets

# Überprüfen der Datentypen
display(final_combined_df.dtypes)

# Sicherstellen, dass relevante Metriken numerisch sind
final_combined_df['TA Avg (m)'] = pd.to_numeric(final_combined_df['TA Avg (m)'], errors='coerce')
final_combined_df['RSRP Avg (dBm)'] = pd.to_numeric(final_combined_df['RSRP Avg (dBm)'], errors='coerce')
final_combined_df['RSRQ Avg (dB)'] = pd.to_numeric(final_combined_df['RSRQ Avg (dB)'], errors='coerce')
final_combined_df['area_m2'] = pd.to_numeric(final_combined_df['area_m2'], errors='coerce')

# Segmentierung in 'normal' und 'buffered' Datensätze
normal_df = final_combined_df[final_combined_df['type'] == 'normal']
buffered_df = final_combined_df[final_combined_df['type'] == 'buffered']

# Liste relevanter Metriken zur Analyse
metrics = ['TA Avg (m)', 'RSRP Avg (dBm)', 'RSRQ Avg (dB)', 'area_m2']

# Berechnung von Mittelwert, Median und Standardabweichung für jede Metrik in den beiden Gruppen
normal_stats = normal_df[metrics].agg(['mean', 'median', 'std'])
buffered_stats = buffered_df[metrics].agg(['mean', 'median', 'std'])

# Anzeigen der statistischen Werte für beide Gruppen
print("Statistiken für die Hotel-Daten:")
display(normal_stats)

print("\nStatistiken für die Buffered Polygon-Daten:")
display(buffered_stats)
```

## Interpretation der Ergebnisse
Die Ergebnisse zeigen einen Vergleich der wichtigsten Metriken zwischen den tatsächlichen Hotelbereichen (normal) und den gepufferten Bereichen (buffered polygons). Wir betrachten die Mittelwerte, Mediane und Standardabweichungen für die Metriken **Timing Advance (TA)**, **RSRP**, **RSRQ** und die **Polygonfläche (area_m2)**.

### Timing Advance (TA)
- **Normal (Hotel-Daten)**:
    - Mittelwert: 467.34 m
    - Median: 301.76 m
    - Standardabweichung: 1115.79 m

- **Buffered Polygon-Daten**:
    - Mittelwert: 312.11 m
    - Median: 267.56 m
    - Standardabweichung: 205.84 m

**Interpretation**: Der Mittelwert und der Median für das **Timing Advance** in den gepufferten Polygonen ist niedriger als in den normalen Hotelbereichen. Dies deutet darauf hin, dass die gepufferten Bereiche tendenziell näher an den Mobilfunkmasten liegen als die tatsächlichen Hotelbereiche. Die höhere Standardabweichung bei den normalen Daten zeigt, dass es in den Hotelbereichen eine größere Variation in der Entfernung zu den Basisstationen gibt.

### RSRP (Reference Signal Received Power)
- **Normal (Hotel-Daten)**:
    - Mittelwert: -94.89 dBm
    - Median: -94.81 dBm
    - Standardabweichung: 10.21 dBm

- **Buffered Polygon-Daten**:
    - Mittelwert: -93.49 dBm
    - Median: -93.37 dBm
    - Standardabweichung: 9.40 dBm

**Interpretation**: Die **RSRP**-Werte (Signalstärke) in den gepufferten Bereichen sind im Mittelwert und Median etwas besser (höher) als in den normalen Hotelbereichen. Dies könnte darauf hindeuten, dass die Umgebung um die Hotels herum eine bessere Signalstärke aufweist als die Hotels selbst. Auch die geringere Standardabweichung bei den gepufferten Daten deutet auf eine etwas konsistentere Signalstärke hin.

### RSRQ (Reference Signal Received Quality)
- **Normal (Hotel-Daten)**:
    - Mittelwert: -9.99 dB
    - Median: -9.88 dB
    - Standardabweichung: 1.80 dB

- **Buffered Polygon-Daten**:
    - Mittelwert: -9.94 dB
    - Median: -9.87 dB
    - Standardabweichung: 1.60 dB

**Interpretation**: Die **RSRQ**-Werte (Signalqualität) zeigen kaum Unterschiede zwischen den normalen Hotelbereichen und den gepufferten Polygonen. Die Werte sind in beiden Datensätzen ähnlich, was darauf hindeutet, dass die Signalqualität innerhalb und um die Hotels herum vergleichbar ist.

### Polygonfläche (area_m2)
- **Normal (Hotel-Daten)**:
    - Mittelwert: 1258.35 m²
    - Median: 712.68 m²
    - Standardabweichung: 2927.15 m²

- **Buffered Polygon-Daten**:
    - Mittelwert: 1054.01 m²
    - Median: 502.56 m²
    - Standardabweichung: 1690.31 m²

**Interpretation**: Die **Fläche der Polygone** ist bei den normalen Hotel-Daten im Mittel größer als bei den gepufferten Daten, was überraschend erscheinen mag. Ein Grund hierfür könnte sein, dass einige sehr große Hotelpolygone den Durchschnitt der normalen Hotelbereiche stark beeinflussen. Die hohe Standardabweichung unterstützt diese Annahme. Andererseits zeigt der niedrigere Median, dass die meisten Hotelpolygone tatsächlich kleiner sind als die gepufferten Polygone, und nur einige große Hotelbereiche den Mittelwert erhöhen.

### Zusammenfassung:
- Die **Timing Advance**-Werte sind in den gepufferten Bereichen geringer, was darauf hindeutet, dass diese Bereiche näher an den Mobilfunkmasten liegen.

- Die **Signalstärke (RSRP)** ist in den gepufferten Bereichen tendenziell besser als in den Hotelbereichen.

- Die **Signalqualität (RSRQ)** zeigt keine signifikanten Unterschiede zwischen den beiden Datensätzen.

- Die **Flächen** der normalen Hotelpolygone sind im Mittel größer, allerdings zeigt der Median, dass die meisten Hotelpolygone tatsächlich kleiner als die gepufferten Polygone sind.

Diese Unterschiede könnten auf die spezifische Geometrie der Hotelbereiche und deren Umgebung sowie auf die Netzwerkkonfiguration hinweisen.

# Explorative Datenanalyse (EDA)
## Univariate Analyse
In diesem Abschnitt untersuchen wir die Verteilung einzelner Variablen (z.B. TA, RSRP, RSRQ) im Datensatz. Dies gibt uns Einblicke in die Verteilung der Daten und zeigt mögliche Ausreißer oder Anomalien.

### Verteilung der Variable TA
```{python}
#| label: univariate analysis - ta histogram

# Zuerst prüfen, ob die Spalten bereits numerisch sind
if final_combined_df['RSRP Avg (dBm)'].dtype == 'object':
    final_combined_df['RSRP Avg (dBm)'] = final_combined_df['RSRP Avg (dBm)'].str.replace(',', '').astype(float)
else:
    final_combined_df['RSRP Avg (dBm)'] = final_combined_df['RSRP Avg (dBm)'].astype(float)

if final_combined_df['TA Avg (m)'].dtype == 'object':
    final_combined_df['TA Avg (m)'] = final_combined_df['TA Avg (m)'].str.replace(',', '').astype(float)
else:
    final_combined_df['TA Avg (m)'] = final_combined_df['TA Avg (m)'].astype(float)

# Erstellen eines Histogramms für TA
plt.figure(figsize=(8, 6))
sns.histplot(final_combined_df['TA Avg (m)'], bins=30, kde=True)
plt.title('Verteilung von Timing Advance (TA)')
plt.xlabel('TA (m)')
plt.ylabel('Anzahl')
plt.grid(True)
plt.show()
```

Die Verteilung der Variable **Timing Advance (TA)** zeigt eine stark rechtssteile Verteilung, bei der die meisten Werte im Bereich von 0 bis 500 Metern liegen. Dies bedeutet, dass sich die Mehrheit der Mobilfunkgeräte relativ nahe an den Basisstationen befindet, was zu geringeren TA-Werten führt. Gleichzeitig sind einige extreme Werte sichtbar, die über 2000 Meter hinausgehen. Diese hohen TA-Werte repräsentieren Mobilfunkgeräte, die weiter entfernt von der Basisstation sind.

```{python}
#| label: univariate analysis - ta boxplot

# Boxplot für TA (Timing Advance)
plt.figure(figsize=(10, 6))
sns.boxplot(x=final_combined_df['TA Avg (m)'])
plt.title('Boxplot von Timing Advance (TA)')
plt.xlabel('TA (m)')
plt.grid(True)
plt.show()
```

Im **Boxplot** ist deutlich erkennbar, dass es eine Vielzahl von Ausreißern gibt, die sich über den Bereich von 2000 bis 8000 Metern erstrecken. Diese Ausreißer deuten auf eine ungleichmäßige Verteilung der Distanzen zwischen den Mobilfunkgeräten und den Basisstationen hin. In einem der nächsten Schritte wird eine Bereinigung der Ausreißer notwendig sein, um die Analyse der TA-Werte zu präzisieren.

### Verteilung der Variablen RSRP und RSRQ
```{python}
#| label: univariate analysis - rsrp histogram

# Histogramm der RSRP
plt.figure(figsize=(8, 6))
sns.histplot(final_combined_df['RSRP Avg (dBm)'], bins=30, kde=True)
plt.title('Verteilung RSRP')
plt.xlabel('RSRP (dBm)')
plt.ylabel('Anzahl')
plt.grid(True)
plt.show()
```

Das Histogramm zeigt die Verteilung der gemessenen **RSRP-Werte (Reference Signal Received Power)**. Die Verteilung der Werte ist leicht rechtssteil, was darauf hindeutet, dass sich die meisten RSRP-Werte zwischen **-120 dBm** und **-80 dBm** bewegen. Dies ist typisch für Mobilfunknetze, bei denen eine akzeptable bis gute Signalstärke im Bereich um **-100 dBm** liegt.

Die Verteilung weist auf eine Konzentration der Daten in einem Bereich hin, der für viele Hotels eine ausreichende Netzabdeckung bietet. Einige Werte sind am unteren Ende des Spektrums verteilt, was auf schlechtere Signalstärken in bestimmten Bereichen hindeuten könnte. Insgesamt zeigt das Histogramm eine erwartete, typische Verteilung für diese Metrik.

```{python}
#| label: univariate analysis - rsrp boxplot

# Boxplot der RSRP
plt.figure(figsize=(10, 6))
sns.boxplot(x=final_combined_df['RSRP Avg (dBm)'])
plt.title('Boxplot RSRP')
plt.xlabel('Pegelwert (dBm)')
plt.grid(True)
```

Der Boxplot **der RSRP-Werte** zeigt eine ähnliche Verteilung wie das Histogramm, jedoch verdeutlicht er auch das Vorhandensein von Ausreißern. Die Box des Boxplots, die den **Interquartilsbereich (IQR)** darstellt, zeigt, dass der Großteil der RSRP-Werte zwischen **-110 dBm** und **-90 dBm** liegt, was als moderate bis gute Signalstärke angesehen werden kann.

Die wenigen Punkte außerhalb der "Whiskers" repräsentieren **Ausreißer**, die auf besonders schlechte Signalbedingungen hinweisen könnten. Diese Ausreißer werden in späteren Analyseschritten noch bereinigt, um eine genauere Auswertung zu ermöglichen.

```{python}
#| label: univariate analysis - rsrq histogram

# Histogramm der RSRQ
plt.figure(figsize=(8, 6))
sns.histplot(final_combined_df['RSRQ Avg (dB)'], bins=30, kde=True)
plt.title('Verteilung RSRQ')
plt.xlabel('RSRQ (dB)')
plt.ylabel('Anzahl')
plt.grid(True)
plt.show()
```

Das Histogramm zeigt die Verteilung der gemessenen **RSRQ-Werte (Reference Signal Received Quality)**. Die Verteilung der Daten ist symmetrisch und konzentriert sich um einen Mittelwert von etwa **-10 dB**. Die meisten Werte liegen zwischen **-12 dB** und **-8 dB**, was auf eine durchschnittliche bis gute Signalqualität hinweist.

Diese Verteilung entspricht den Erwartungen in Bezug auf die Netzqualität in urbanen Gebieten, da RSRQ die Effizienz der genutzten Signalressourcen angibt. Die Werte, die unter **-12 dB** fallen, könnten auf überlastete Netzwerke oder Bereiche mit hoher Interferenz hinweisen.

```{python}
#| label: univariate analysis - rsrq boxplot

# Boxplot RSRQ
plt.figure(figsize=(10, 6))
sns.boxplot(x=final_combined_df['RSRQ Avg (dB)'])
plt.title('Boxplot RSRQ')
plt.xlabel('Pegelwert (dB)')
plt.grid(True)
```

Der Boxplot der **RSRQ-Werte** zeigt die typische Verteilung der Daten mit einer relativ engen Box, die den **Interquartilsabstand (IQR)** darstellt. Die Werte für RSRQ konzentrieren sich zwischen **-12 dB** und **-8 dB**, was auf eine gute Signalqualität in den meisten Bereichen hinweist.

Einige wenige Punkte liegen außerhalb der Whiskers des Boxplots, was darauf hinweist, dass es **Ausreißer** gibt. Diese können auf Regionen mit schlechterer Signalqualität oder höhere Interferenzen hinweisen. Auch hier werden diese Ausreißer in späteren Analysen bereinigt.

### Verteilung der Variable Polygon-Area
```{python}
#| label: univariate analysis - area histogram

# Histogramm der Polygonflächen
plt.figure(figsize=(8, 6))
sns.histplot(final_combined_df['area_m2'], bins=30, kde=True)
plt.title('Verteilung der Polygonflächen')
plt.xlabel('Fläche (m²)')
plt.ylabel('Anzahl')
plt.grid(True)
plt.show()
```

Das **Histogramm** der Polygonflächen zeigt, dass die meisten Polygone in einer sehr kleinen Flächengröße liegen, wobei die Häufigkeit bei niedrigeren Flächenwerten besonders hoch ist. Dies deutet darauf hin, dass viele Polygone eine relativ kleine Fläche aufweisen, was zu erwarten ist, da es sich um Hotelbereiche oder vergleichbare Zonen handelt. Die Verteilung ist stark nach rechts verzerrt (rechtsschief), was bedeutet, dass einige sehr große Flächen existieren, aber diese sind selten.

Dies könnte ein Hinweis auf Ausreißer in den Daten sein, die im späteren Verlauf ebenfalls bereinigt werden müssen.

```{python}
#| label: univariate analysis - area boxplot

# Boxplot der Polygonflächen
plt.figure(figsize=(10, 6))
sns.boxplot(x=final_combined_df['area_m2'])
plt.title('Boxplot der Polygonflächen')
plt.xlabel('Fläche (m²)')
plt.grid(True)
```

Der **Boxplot** bestätigt die Beobachtungen aus dem Histogramm. Der Großteil der Polygonflächen liegt in einem engen Bereich um den Medianwert, während einige Werte als Ausreißer erkennbar sind, die sich signifikant von der restlichen Verteilung unterscheiden. Diese Ausreißer zeigen Polygone mit besonders großen Flächen, die deutlich von der allgemeinen Verteilung abweichen.

Diese Ausreißer werden im nächsten Schritt der Analyse bereinigt, um eine genauere Datenbasis zu schaffen.

## Datenbereinigung
### Entfernen von Ausreißern bei TA
In diesem Abschnitt bereinigen wir die Timing Advance (TA)-Daten, indem wir Ausreißer identifizieren und entfernen. Ausreißer sind extreme Werte, die weit außerhalb des normalen Bereichs der Daten liegen und die Analyse verzerren könnten.

#### Vorgehensweise:
Um Ausreißer zu identifizieren, verwenden wir die **Interquartilsabstand (IQR)**-Methode. Der IQR ist der Abstand zwischen dem 1. Quartil (Q1, 25%-Perzentil) und dem 3. Quartil (Q3, 75%-Perzentil). Dieser Bereich umfasst die mittleren 50% der Daten.

1. **Berechnung von Q1 und Q3**: Wir berechnen das 1. und 3. Quartil der Flächenverteilung.

2. **Berechnung des Interquartilsabstands (IQR)**: Der IQR wird als Differenz zwischen Q3 und Q1 berechnet.

3. **Definition der Grenzen für Ausreißer**: Werte, die mehr als das 1,5-fache des IQR unterhalb von Q1 oder oberhalb von Q3 liegen, werden als Ausreißer betrachtet.

4. **Entfernen von Ausreißern**: Alle TA-Werte, die außerhalb der definierten Grenzen liegen, werden entfernt.
```{python}
#| label: removal of TA outliers

# Sicherstellen, dass alle Werte in 'TA Avg (m)' numerisch sind, ungültige Werte werden in NaN umgewandelt
final_combined_df['TA Avg (m)'] = pd.to_numeric(final_combined_df['TA Avg (m)'], errors='coerce')

# Berechnung des 1. Quartils (Q1) und des 3. Quartils (Q3) für TA
Q1_ta = final_combined_df['TA Avg (m)'].quantile(0.25)
Q3_ta = final_combined_df['TA Avg (m)'].quantile(0.75)
IQR_ta = Q3_ta - Q1_ta

# Definition der Schwellenwerte für TA
lower_bound_ta = Q1_ta - 1.5 * IQR_ta
upper_bound_ta = Q3_ta + 1.5 * IQR_ta

# Entfernen von Ausreißern (TA-Werte außerhalb der definierten Grenzen)
filtered_final_combined_df = final_combined_df[(final_combined_df['TA Avg (m)'] >= lower_bound_ta) & (final_combined_df['TA Avg (m)'] <= upper_bound_ta)]

# Anzeigen der bereinigten Daten
print(f"Vor dem Entfernen der Ausreißer bei TA: {len(final_combined_df)} Einträge")
print(f"Nach dem Entfernen der Ausreißer bei TA: {len(filtered_final_combined_df)} Einträge")

# Histogramm der bereinigten TA-Daten
plt.figure(figsize=(8, 6))
sns.histplot(filtered_final_combined_df['TA Avg (m)'], bins=30, kde=True)
plt.title('Verteilung der bereinigten Timing Advance (TA) Werte')
plt.xlabel('TA (m)')
plt.ylabel('Anzahl')
plt.grid(True)
plt.show()

# Boxplot der bereinigten TA-Daten
plt.figure(figsize=(10, 6))
sns.boxplot(x=filtered_final_combined_df['TA Avg (m)'])
plt.title('Boxplot der bereinigten Timing Advance (TA) Werte')
plt.xlabel('TA (m)')
plt.grid(True)
plt.show()
```

### Entfernen von Ausreißern bei den Polygonflächen
In diesem Abschnitt bereinigen wir die Polygonflächen-Daten, indem wir Ausreißer identifizieren und entfernen. Ausreißer sind extreme Werte, die weit außerhalb des normalen Bereichs der Daten liegen und die Analyse verzerren könnten.

#### Vorgehensweise:
Um Ausreißer zu identifizieren, verwenden wir ebenfalls die **Interquartilsabstand (IQR)-Methode**.
```{python}
#| label: removal of area outliers

# Berechnung des 1. Quartils (Q1) und des 3. Quartils (Q3)
Q1 = filtered_final_combined_df['area_m2'].quantile(0.25)
Q3 = filtered_final_combined_df['area_m2'].quantile(0.75)
IQR = Q3 - Q1

# Definition der Schwellenwerte für die Fläche
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Entfernen von Ausreißern (Polygone außerhalb der definierten Grenzen)
new_filtered_final_combined_df = filtered_final_combined_df[(final_combined_df['area_m2'] >= lower_bound) & (final_combined_df['area_m2'] <= upper_bound)]

# Anzeigen der bereinigten Daten
print(f"Vor dem Entfernen der Ausreißer: {len(filtered_final_combined_df)} Polygone")
print(f"Nach dem Entfernen der Ausreißer: {len(new_filtered_final_combined_df)} Polygone")

# Histogramm der bereinigten Polygonflächen
plt.figure(figsize=(8, 6))
sns.histplot(new_filtered_final_combined_df['area_m2'], bins=30, kde=True)
plt.title('Verteilung der bereinigten Polygonflächen')
plt.xlabel('Fläche (m²)')
plt.ylabel('Anzahl')
plt.grid(True)
plt.show()

# Boxplot der bereinigten Polygonflächen
plt.figure(figsize=(10, 6))
sns.boxplot(x=new_filtered_final_combined_df['area_m2'])
plt.title('Boxplot der bereinigten Polygonflächen')
plt.xlabel('Fläche (m²)')
plt.grid(True)
plt.show()
```

### Entfernen von Duplikaten
In diesem Schritt entfernen wir alle potenziellen Duplikate im Datensatz, die möglicherweise bei der Kombination von normalem und gepuffertem Polygon-Datensatz entstanden sind. Dies ist wichtig, um sicherzustellen, dass keine doppelten Einträge die Analyse verfälschen.

#### Vorgehensweise:
- **Überprüfung auf Duplikate**: Zuerst überprüfen wir, ob der kombinierte Datensatz doppelte Zeilen enthält.

- **Entfernung von Duplikaten**: Falls Duplikate vorhanden sind, entfernen wir diese, um die Integrität des Datensatzes zu gewährleisten.
```{python}
#| label: remove duplicates

# Überprüfen, ob Duplikate im Datensatz vorhanden sind
duplicate_count = new_filtered_final_combined_df.duplicated().sum()
print(f"Anzahl der Duplikate im Datensatz: {duplicate_count}")

# Falls Duplikate vorhanden sind, werden diese entfernt
if duplicate_count > 0:
    new_filtered_final_combined_df = new_filtered_final_combined_df.drop_duplicates()
    print(f"Anzahl der Einträge nach dem Entfernen von Duplikaten: {len(final_combined_df)}")
else:
    print("Keine Duplikate im Datensatz gefunden.")
```

### Finden von NA’s
In diesem Abschnitt untersuchen wir, ob es fehlende Werte (NA’s) in den Daten gibt. Fehlende Werte können die Analyse verfälschen und müssen behandelt werden.

#### Vorgehensweise:
Wir verwenden die Methode `.isnull()` in Kombination mit `.sum()`, um zu überprüfen, wie viele fehlende Werte in jeder Spalte vorhanden sind.
```{python}
#| label: find NAs

# Überprüfen, wie viele fehlende Werte es in jeder Spalte gibt
na_counts = new_filtered_final_combined_df.isnull().sum()
print(na_counts)
```

### Umgang mit fehlenden Werten
Nachdem wir die fehlenden Werte identifiziert haben, überlegen wir, wie wir mit diesen Werten umgehen. Mögliche Strategien sind:

- **Entfernen**: Entfernen von Zeilen oder Spalten mit vielen fehlenden Werten.

- **Imputation**: Ersetzen fehlender Werte durch statistische Kennzahlen (z.B. Mittelwert oder Median).

In diesem Fall entscheiden wir uns für die Imputation der fehlenden Werte mithilfe des Medians.
```{python}
#| label: handle NAs

# Nur numerische Spalten auswählen
numeric_columns = final_combined_df.select_dtypes(include=[np.number]).columns

# Ersetzen der fehlenden Werte in numerischen Spalten mit dem Median
final_combined_df[numeric_columns] = final_combined_df[numeric_columns].fillna(final_combined_df[numeric_columns].median())

# Überprüfen, ob noch fehlende Werte vorhanden sind
na_counts_after = final_combined_df.isnull().sum()
print(na_counts_after)
```

## Bivariate Analyse: Zusammenhang zwischen Timing Advance (TA) und Signalqualität (RSRP, RSRQ)
In diesem Abschnitt untersuchen wir den Zusammenhang zwischen **Timing Advance (TA)** und den Signalqualitätsmetriken **RSRP** (Reference Signal Received Power) und **RSRQ** (Reference Signal Received Quality). Wir erwarten, dass ein höheres Timing Advance, welches eine größere Entfernung zwischen dem Mobilfunkgerät und der Basisstation anzeigt, zu einer schlechteren Signalqualität führt.

### Scatterplot TA vs. RSRP
Der folgende Scatterplot zeigt den Zusammenhang zwischen **Timing Advance (TA)** und **RSRP**. Hier wird deutlich, dass bei zunehmendem TA-Wert der RSRP-Wert abnimmt, was auf eine Verschlechterung der empfangenen Signalstärke hindeutet.
```{python}
#| label: scatterplot ta and rsrp

# Scatterplot mit Punkten und Regressionslinie
plt.figure(figsize=(9, 6))
sns.scatterplot(x=new_filtered_final_combined_df['TA Avg (m)'], y=new_filtered_final_combined_df['RSRP Avg (dBm)'], alpha=0.5, s=20)  # scatterplot für die Punkte
sns.regplot(x=new_filtered_final_combined_df['TA Avg (m)'], y=new_filtered_final_combined_df['RSRP Avg (dBm)'], scatter=False, color='blue', line_kws={'linewidth':1.5})  # regplot für die Regressionslinie

plt.title('Scatterplot TA vs. RSRP mit Regressionslinie')
plt.xlabel('Timing Advance (m)')
plt.ylabel('RSRP (dBm)')
plt.grid(True)
plt.show()

# Berechnung der Pearson-Korrelation
pearson_corr_ta_rsrp = new_filtered_final_combined_df['TA Avg (m)'].corr(new_filtered_final_combined_df['RSRP Avg (dBm)'])
print(f"Pearson-Korrelation TA vs. RSRP: {pearson_corr_ta_rsrp}")
```

- **Beobachtung**: Ein deutlich negativer Trend ist erkennbar. Mit zunehmendem Timing Advance verschlechtert sich die Signalstärke (niedrigere RSRP-Werte). Die Punkte konzentrieren sich hauptsächlich im Bereich niedriger TA-Werte, während bei höheren TA-Werten eine geringere Dichte vorliegt.

- **Pearson-Korrelation**: Die Pearson-Korrelation zwischen TA und RSRP beträgt etwa **-0.53**, was auf einen mittleren, aber signifikanten negativen Zusammenhang hinweist. Dieser Korrelationswert zeigt, dass größere Entfernungen (höheres TA) mit schlechterem Empfang (niedrigere RSRP-Werte) einhergehen.

### Scatterplot TA vs. RSRQ
Dieser Scatterplot visualisiert den Zusammenhang zwischen **Timing Advance (TA)** und **RSRQ**. Auch hier ist ein negativer Trend erkennbar, wenn auch weniger ausgeprägt als beim Zusammenhang zwischen **TA** und **RSRP**.
```{python}
#| label: scatterplot ta and rsrq

# Scatterplot mit Punkten und Regressionslinie
plt.figure(figsize=(9, 6))
sns.scatterplot(x=new_filtered_final_combined_df['TA Avg (m)'], y=new_filtered_final_combined_df['RSRQ Avg (dB)'], alpha=0.5, s=20)
sns.regplot(x=new_filtered_final_combined_df['TA Avg (m)'], y=new_filtered_final_combined_df['RSRQ Avg (dB)'], scatter=False, color='blue', line_kws={'linewidth':1.5})

# Titel und Achsenbeschriftungen
plt.title('Scatterplot TA vs. RSRQ')
plt.xlabel('Timing Advance (m)')
plt.ylabel('RSRQ (dB)')
plt.grid(True)
plt.show()

# Berechnung der Pearson-Korrelation
pearson_corr_ta_rsrq = new_filtered_final_combined_df['TA Avg (m)'].corr(new_filtered_final_combined_df['RSRQ Avg (dB)'])
print(f"Pearson-Korrelation TA vs. RSRQ: {pearson_corr_ta_rsrq}")
```

- **Beobachtung**: Der **RSRQ**-Wert nimmt ebenfalls tendenziell ab, je größer der **TA**-Wert ist, was eine Verschlechterung der Signalqualität bei größerer Entfernung zur Basisstation anzeigt. Allerdings ist die Streuung der Punkte größer, und es gibt weniger starke Korrelationen im mittleren Bereich der TA-Werte.

- **Pearson-Korrelation**: Die Pearson-Korrelation zwischen **TA** und **RSRQ** beträgt **-0.35**, was auf einen schwachen negativen Zusammenhang hinweist. Es gibt eine leichte Tendenz, dass mit größerer Entfernung zur Basisstation (höheres TA) die Signalqualität sinkt, aber der Zusammenhang ist noch schwächer als bei **RSRP**.

### Interpretation der Ergebnisse
Beide Scatterplots und die Pearson-Korrelationen zeigen, dass ein höheres **Timing Advance (TA)** tendenziell mit einer Verschlechterung der Signalqualität in Bezug auf **RSRP** und **RSRQ** einhergeht. Der Zusammenhang ist jedoch nur mäßig ausgeprägt, was darauf hindeutet, dass neben der Entfernung zur Basisstation auch andere Faktoren die Signalqualität beeinflussen.

**RSRP** zeigt einen etwas stärkeren Zusammenhang mit **TA** als **RSRQ**, was darauf hindeuten könnte, dass die Signalstärke stärker von der Entfernung zur Basisstation abhängt als die Signalqualität (**RSRQ**), welche möglicherweise durch weitere Faktoren wie Interferenzen beeinflusst wird.

# Modellierung und Vorhersagen
## Zielvariable festlegen
Bestimmung der zu modellierenden Zielvariable, z.B. RSRP oder RSRQ.

## Modellauswahl
Auswahl geeigneter Machine-Learning-Modelle wie lineare Regression, Entscheidungsbäume oder Random Forest.

## Modelltraining und Evaluierung
Training und Evaluierung der Modelle auf Basis der Daten, z.B. mit Kreuzvalidierung und Metriken wie R² und MSE.

# Fazit und Ausblick
## Zusammenfassung
Zusammenfassung der wichtigsten Erkenntnisse aus der Analyse und Modellierung.

## Ausblick
Diskussion möglicher Erweiterungen der Analyse und weiterer Schritte.